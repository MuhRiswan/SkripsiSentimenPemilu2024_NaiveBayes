{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvB3/d91tF61fqPhlphkg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhRiswan/SkripsiSentimenPemilu2024_NaiveBayes/blob/main/skripsi_analisis_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analisis Sentimen Pemberitaan hasil Rekapitulasi Pemilu presiden 2024**\n",
        "\n",
        "\n",
        "\n",
        "Tahapan Analisis Data Sentimen\n",
        "\n",
        "\n",
        "1.   Data Selection\n",
        "     * Normalisasi\n",
        "     * Labeling\n",
        "2.   PreProcessing\n",
        "\n",
        "     * Cleaning\n",
        "     * Stopword\n",
        "     * Tokenize\n",
        "     * Stemming     \n",
        "3.   Visualiasi\n",
        "4.   Klasifikasi Sentimen\n",
        "5.   Evaluation"
      ],
      "metadata": {
        "id": "cpqbr_Y-tAxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select Data"
      ],
      "metadata": {
        "id": "B2KSTBKFtN5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m2FiFrltAMQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/dataSkripsi.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-0QziFh9tK4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['username', 'comment', 'commentDate']]\n",
        "df"
      ],
      "metadata": {
        "id": "I8WRZzdVtMsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Labeling data\n",
        "!pip install transformers\n",
        "!pip install googletrans==3.1.0a0\n",
        "from googletrans.client import Translator\n",
        "translator  = Translator()\n",
        "\n",
        "from transformers import pipeline\n",
        "sentiment_classifier = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "XSReXuUjtRZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['comments'] = df['comment'].str.encode('ascii', 'ignore').apply(translator.translate, dest='en')\n",
        "df['comments'] = df['comments'].apply(getattr, args=('text',))"
      ],
      "metadata": {
        "id": "PkBxGcFitS_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/dataClean.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "I-3klAajtV2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "17XePR5KtY7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cleaning\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Fungsi untuk membersihkan komentar Instagram\n",
        "def clean_comment_instagram(data):\n",
        "    if pd.isna(data): # Check if data is NaN\n",
        "        return ''\n",
        "    # Menghapus karakter khusus macam @mentions, #hastag, url, dan emote\n",
        "    data = re.sub(r'@[A-Za-z0-9_]+', '', data)\n",
        "    data = re.sub(r'#\\w+', '', data)\n",
        "    data = re.sub(r'RT[\\s]+', '', data)\n",
        "    data = re.sub(r'https?://\\S+', '', data)\n",
        "    data = re.sub(r'[^A-Za-z0-9]', ' ', data)\n",
        "\n",
        "    # Menghapus tanda baca\n",
        "    data = data.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Normalisasi teks\n",
        "    # data = data.lower() # Mengubah menjadi lowercase\n",
        "    data = re.sub(r'\\s+', ' ', data).strip() # Menghapus spasi berlebih\n",
        "\n",
        "    # Menghapus angka yang menempel pada kata\n",
        "    data = re.sub(r'\\d+', '', data)\n",
        "\n",
        "    return data # Mengembalikan data tanpa koreksi typo\n",
        "\n",
        "# Menambahkan kolom baru 'Cleaning' dengan data yang telah dibersihkan\n",
        "df['cleaning'] = df['comment'].apply(clean_comment_instagram)\n",
        "\n",
        "# Menghapus duplikat dan data kosong\n",
        "df = df.drop_duplicates(subset=['cleaning'])\n",
        "df = df.dropna()\n",
        "\n",
        "# Memilih kolom 'comment', 'label', dan 'Cleaning'\n",
        "df = df[['comment', 'label', 'cleaning']]\n",
        "\n",
        "# Menampilkan 5 baris pertama untuk memastikan kolom baru telah ditambahkan\n",
        "df.head()"
      ],
      "metadata": {
        "id": "GkoXCUMptaWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - Case Folding\n",
        "\n",
        "df['case_folding'] = df['cleaning'].str.lower()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ja8aAB0htdF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stopword Removal\n",
        "!pip install Sastrawi"
      ],
      "metadata": {
        "id": "_pipBmlUteM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
        "\n",
        "more_stop_words = [\"indonesia\", \"indonesian\"]\n",
        "\n",
        "# Buat instance dari StopWordRemoverFactory\n",
        "factory = StopWordRemoverFactory()\n",
        "\n",
        "# Ambil daftar stopwords bawaan dari Sastrawi\n",
        "stop_words = factory.get_stop_words()\n",
        "\n",
        "# Tambahkan stopwords tambahan ke daftar stopwords\n",
        "stop_words.extend(more_stop_words)\n",
        "\n",
        "# Buat array dictionary untuk stopwords\n",
        "new_array = ArrayDictionary(stop_words)\n",
        "\n",
        "# Buat instance dari StopWordRemover dengan stopwords yang telah diperbarui\n",
        "stop_words_remover_new = StopWordRemover(new_array)\n",
        "\n",
        "# Fungsi untuk menghapus stopwords dari teks\n",
        "def stopword(str_text):\n",
        "    str_text = stop_words_remover_new.remove(str_text)\n",
        "    return str_text\n",
        "\n",
        "# Terapkan fungsi stopword ke kolom 'comment' pada DataFrame\n",
        "df['stopword_removal'] = df['case_folding'].apply(stopword)\n",
        "\n",
        "# Lihat beberapa baris hasil untuk memastikan\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uDjRxMd-tfJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing\n",
        "df['tokenized'] = df['stopword_removal'].apply(lambda x:x.split())\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SnSeEF2LtilC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# - Stemming\n",
        "\n",
        "# Mengimpor pustaka yang diperlukan\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import pandas as pd\n",
        "\n",
        "# Membuat instance dari StemmerFactory dan Stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Fungsi untuk melakukan stemming pada teks\n",
        "def stemming(text_cleaning):\n",
        "    # Menstem setiap kata dalam teks yang sudah dibersihkan\n",
        "    stemmed_words = [stemmer.stem(word) for word in text_cleaning]\n",
        "    # Menggabungkan kembali kata-kata yang sudah di-stem menjadi satu string\n",
        "    return \" \".join(stemmed_words)\n",
        "\n",
        "# Asumsikan 'tokenized' adalah DataFrame yang sudah berisi tokenisasi komentar\n",
        "df['comment'] = df['tokenized'].apply(stemming)\n",
        "# Menerapkan stemming pada setiap tokenized comment\n",
        "tokenized = df['comment']\n",
        "\n",
        "# Menyimpan hasil preprocessing ke file CSV\n",
        "tokenized.to_csv(\"/content/hasilPreProcessingData.csv\", index=False)\n",
        "\n",
        "# Membaca kembali hasil preprocessing dari file CSV\n",
        "data = pd.read_csv(\"/content/hasilPreProcessingData.csv\", encoding='latin1')\n"
      ],
      "metadata": {
        "id": "PVxUGY9ltjsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF"
      ],
      "metadata": {
        "id": "oAZWtDU0tmbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer"
      ],
      "metadata": {
        "id": "F0sJO-2Stk3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Inisialisasi TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Sesuaikan dengan data 'comment' yang telah di-preprocessing dan transformasikan\n",
        "tfidf = tfidf_vectorizer.fit_transform(df['comment'])  # Ganti 'df' dengan nama DataFrame Anda yang berisi data yang telah di-preprocessing\n",
        "\n",
        "# Dapatkan daftar fitur (kata-kata)\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Buat DataFrame untuk menampilkan kata dan bobotnya\n",
        "df_tfidf = pd.DataFrame(tfidf.toarray(), columns=feature_names)\n",
        "\n",
        "# Tampilkan DataFrame\n",
        "print(df_tfidf)"
      ],
      "metadata": {
        "id": "dIHdS22VtrzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mempelajari kosakata unik\n",
        "comment = df['comment']\n",
        "cv = CountVectorizer()\n",
        "term_fit = cv.fit(comment)\n",
        "#mencetak ukuran kosakata, yaitu jumlah total kata unik yang ditemukan dalam data comment\n",
        "print(len(term_fit.vocabulary_))"
      ],
      "metadata": {
        "id": "jNaAu29jtswG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#menampilkan kosakata dari kata-kata unik dan nilainya adalah indeks numerik yang sesuai yang diberikan kepada setiap kata\n",
        "term_fit.vocabulary_"
      ],
      "metadata": {
        "id": "GeQMP9uWtuLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#menghitung seberapa sering setiap kata muncul dalam setiap komentar.\n",
        "#Kolom pertama  = jumlah dokumen\n",
        "#Kolom kedua = letak katanya\n",
        "#Kolom ketika = hasil dari tf\n",
        "term_frequency_all = term_fit.transform(comment)\n",
        "print(term_frequency_all)"
      ],
      "metadata": {
        "id": "KgsLfQ5GtvSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "term_frequency = term_fit.transform([comment_tf])\n",
        "print(term_frequency)"
      ],
      "metadata": {
        "id": "R4oN4A0ftwlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#menghitung seberapa sering setiap kata muncul dalam setiap komentar dan menyimpan hasilnya dalam bentuk tabel.\n",
        "dokumen = term_fit.transform(comment)\n",
        "\n",
        "#menghitung bobot setiap kata berdasarkan seberapa sering kata tersebut muncul dalam semua komentar. Kata yang jarang muncul akan memiliki bobot yang lebih tinggi.\n",
        "tfidf_transformer = TfidfTransformer().fit(dokumen)\n",
        "print(tfidf_transformer.idf_)\n",
        "\n",
        "#menghitung bobot akhir setiap kata dalam komentar tertentu dengan mempertimbangkan bobot yang dihitung sebelumnya\n",
        "tfidf = tfidf_transformer.transform(term_frequency)\n",
        "print(tfidf)"
      ],
      "metadata": {
        "id": "0kAx6dJ6tyKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Algoritma Naive Bayes"
      ],
      "metadata": {
        "id": "UoCcDs7Kt2kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Spliting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "9GMZwcvKt0up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data training dan testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['comment'], df['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Inisialisasi TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n"
      ],
      "metadata": {
        "id": "RfWNrcC1t6ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "LimFWQq4t8K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit dan transform data training\n",
        "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
        "\n",
        "# Hanya transform data testing\n",
        "x_test_tfidf = tfidf_vectorizer.transform(x_test)\n",
        "\n",
        "# Inisialisasi dan latih model Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train_tfidf, y_train)\n",
        "\n",
        "# Prediksi data testing\n",
        "y_pred = nb.predict(x_test_tfidf)"
      ],
      "metadata": {
        "id": "QiI29R0Xt8ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report # Added the missing import statement\n",
        "\n",
        "# Evaluasi performa model\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}')\n",
        "print('============================================================================')\n",
        "print(classification_report(y_test, y_pred, zero_division=0)) # Changed 'predicted' to 'y_pred'"
      ],
      "metadata": {
        "id": "mWv3VUzht-FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: tolong buatkan code yang manimplkan pie chart dari hasil prediksinya dan setelah data miningnya berisikan hasil true negative dan true positive dan buat keterangannya menggunakan bahsa indonesia serta jumlah datanya ditampilkan disamping pie chart dan jangan terlalu jauh\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ... (Your existing code for data preprocessing, model training, and prediction) ...\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Ekstrak nilai true positive, true negative, false positive, dan false negative\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Data untuk pie chart\n",
        "labels = ['True Positive', 'True Negative']\n",
        "sizes = [tp, tn]\n",
        "\n",
        "# Buat pie chart\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "ax.axis('equal')\n",
        "\n",
        "# Tambahkan judul\n",
        "plt.title('Hasil Actual Prediction')\n",
        "\n",
        "# Menampilkan jumlah data di samping pie chart\n",
        "plt.text(1.2, 0.5, f\"True Positive: {tp}\\nTrue Negative: {tn}\", transform=ax.transAxes)\n",
        "\n",
        "# Tampilkan pie chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uQ3QdP0-uA8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data training dan testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['comment'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n"
      ],
      "metadata": {
        "id": "Bew7MiaZuJeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "yFUfYSlkuL_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit dan transform data training\n",
        "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
        "\n",
        "# Hanya transform data testing\n",
        "x_test_tfidf = tfidf_vectorizer.transform(x_test)\n",
        "\n",
        "# Inisialisasi dan latih model Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train_tfidf, y_train)\n",
        "\n",
        "# Prediksi data testing\n",
        "y_pred = nb.predict(x_test_tfidf)"
      ],
      "metadata": {
        "id": "LgGQw2AkuM4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi performa model\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}')\n",
        "print('============================================================================')\n",
        "print(classification_report(y_test, y_pred, zero_division=0)) # Changed 'predicted' to 'y_pred'"
      ],
      "metadata": {
        "id": "zXmi-YnZuOMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: tolong buatkan code yang manimplkan pie chart dari hasil prediksinya dan setelah data miningnya berisikan hasil true negative dan true positive dan buat keterangannya menggunakan bahsa indonesia serta jumlah datanya ditampilkan disamping pie chart dan jangan terlalu jauh\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ... (Your existing code for data preprocessing, model training, and prediction) ...\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Ekstrak nilai true positive, true negative, false positive, dan false negative\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Data untuk pie chart\n",
        "labels = ['True Positive', 'True Negative']\n",
        "sizes = [tp, tn]\n",
        "\n",
        "# Buat pie chart\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "ax.axis('equal')\n",
        "\n",
        "# Tambahkan judul\n",
        "plt.title('Hasil Actual Prediction')\n",
        "\n",
        "# Menampilkan jumlah data di samping pie chart\n",
        "plt.text(1.2, 0.5, f\"True Positive: {tp}\\nTrue Negative: {tn}\", transform=ax.transAxes)\n",
        "\n",
        "# Tampilkan pie chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "czzT4rzyuOJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data training dan testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['comment'], df['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Inisialisasi TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n"
      ],
      "metadata": {
        "id": "xUH32yCZuOH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "xTnVeBvDuOF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit dan transform data training\n",
        "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
        "\n",
        "# Hanya transform data testing\n",
        "x_test_tfidf = tfidf_vectorizer.transform(x_test)\n",
        "\n",
        "# Inisialisasi dan latih model Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train_tfidf, y_train)\n",
        "\n",
        "# Prediksi data testing\n",
        "y_pred = nb.predict(x_test_tfidf)"
      ],
      "metadata": {
        "id": "o-3fIGl3uODT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi performa model\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}')\n",
        "print('============================================================================')\n",
        "print(classification_report(y_test, y_pred, zero_division=0)) # Changed 'predicted' to 'y_pred'"
      ],
      "metadata": {
        "id": "vekjGG-ZuOAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: tolong buatkan code yang manimplkan pie chart dari hasil prediksinya dan setelah data miningnya berisikan hasil true negative dan true positive dan buat keterangannya menggunakan bahsa indonesia serta jumlah datanya ditampilkan disamping pie chart dan jangan terlalu jauh\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ... (Your existing code for data preprocessing, model training, and prediction) ...\n",
        "\n",
        "# Menghitung confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Ekstrak nilai true positive, true negative, false positive, dan false negative\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Data untuk pie chart\n",
        "labels = ['True Positive', 'True Negative']\n",
        "sizes = [tp, tn]\n",
        "\n",
        "# Buat pie chart\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "ax.axis('equal')\n",
        "\n",
        "# Tambahkan judul\n",
        "plt.title('Hasil Hasil Actual Prediction')\n",
        "\n",
        "# Menampilkan jumlah data di samping pie chart\n",
        "plt.text(1.2, 0.5, f\"True Positive: {tp}\\nTrue Negative: {tn}\", transform=ax.transAxes)\n",
        "\n",
        "# Tampilkan pie chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Jx6OLOX0uN4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualisasi"
      ],
      "metadata": {
        "id": "RhH-yt6DubQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: tolong buatkan code yang hasilnya berisikan hasil sentimen komentar positif & negatif dalam bentuk pie chart besarta tampilkan jumlah datanya, oh ya datanya itu data dari labeling\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hitung jumlah komentar positif dan negatif dari kolom 'label'\n",
        "positive_comments = (df['label'] == 'POSITIVE').sum()\n",
        "negative_comments = (df['label'] == 'NEGATIVE').sum()\n",
        "\n",
        "# Data untuk pie chart\n",
        "labels = ['Positive', 'Negative']\n",
        "sizes = [positive_comments, negative_comments]\n",
        "\n",
        "# Buat pie chart\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "ax.axis('equal')\n",
        "\n",
        "# Tambahkan judul\n",
        "plt.title('Persentase Komentar Positif & Negatif')\n",
        "\n",
        "# Menampilkan jumlah data di samping pie chart\n",
        "plt.text(1.2, 0.5, f\"Positive Comments: {positive_comments}\\nNegative Comments: {negative_comments}\", transform=ax.transAxes)\n",
        "\n",
        "# Tampilkan pie chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XibZ1MNguYLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisasi Kata yang sering muncul"
      ],
      "metadata": {
        "id": "_3keUdw5uhBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_s0 = df[df['label'] == 'NEGATIVE']"
      ],
      "metadata": {
        "id": "3ZlcpMfnueGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_s0['comment'] = train_s0['comment'].fillna('tidak ada komentar')"
      ],
      "metadata": {
        "id": "YJ05slQ1uicw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "VdpH2G1pujW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text_s0 = ' '.join(word for word in train_s0['comment'])\n",
        "wordcloud = WordCloud(background_color='white').generate(all_text_s0)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Komentar Negatif')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2949ENSukYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_s1 = df[df['label'] == 'POSITIVE']\n",
        "train_s1['comment'] = train_s1['comment'].fillna('tidak ada komentar')"
      ],
      "metadata": {
        "id": "wDE9CBM2ulN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text_s1 = ' '.join(word for word in train_s1['comment'])\n",
        "wordcloud = WordCloud(background_color='white').generate(all_text_s1)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Komentar Positif')\n",
        "plt.margins(x=0, y=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D4MunhDtumx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Data\n",
        "scenarios = ['Skenario 90:10', 'Skenario 80:20', 'Skenario 70:30']\n",
        "accuracy = [0.76, 0.75, 0.75]\n",
        "precision = [0.77, 0.75, 0.75]\n",
        "recall = [0.75, 0.74, 0.73]\n",
        "f1_score = [0.75, 0.74, 0.74]\n",
        "\n",
        "# Mengatur lebar bar dan posisi\n",
        "bar_width = 0.2\n",
        "r1 = np.arange(len(scenarios))\n",
        "r2 = [x + bar_width for x in r1]\n",
        "r3 = [x + bar_width for x in r2]\n",
        "r4 = [x + bar_width for x in r3]\n",
        "\n",
        "# Membuat plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(r1, accuracy, color='#ff7f0e', width=bar_width, label='Accuracy')\n",
        "plt.bar(r2, precision, color='#9467bd', width=bar_width, label='Precision')\n",
        "plt.bar(r3, recall, color='#ffbb78', width=bar_width, label='Recall')\n",
        "plt.bar(r4, f1_score, color='#1f77b4', width=bar_width, label='F1-Score')\n",
        "\n",
        "# Menambahkan label dan judul\n",
        "plt.xlabel('Skenario')\n",
        "plt.ylabel('Persentase (%)')\n",
        "plt.title('Perbandingan Evaluasi Antar Skenario')\n",
        "plt.xticks([r + bar_width for r in range(len(scenarios))], scenarios)\n",
        "\n",
        "# Menambahkan nilai di atas setiap bar\n",
        "for i, v in enumerate(accuracy):\n",
        "    plt.text(r1[i], v, f'{v:.2%}', ha='center', va='bottom')\n",
        "for i, v in enumerate(precision):\n",
        "    plt.text(r2[i], v, f'{v:.2%}', ha='center', va='bottom')\n",
        "for i, v in enumerate(recall):\n",
        "    plt.text(r3[i], v, f'{v:.2%}', ha='center', va='bottom')\n",
        "for i, v in enumerate(f1_score):\n",
        "    plt.text(r4[i], v, f'{v:.2%}', ha='center', va='bottom')\n",
        "\n",
        "# Menambahkan legend\n",
        "plt.legend()\n",
        "\n",
        "# Mengatur batas sumbu y\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Menampilkan grafik\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F6GogJBSuoIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}